{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook aim to provide code for embeddings visualization with tensorboard. Embeddings are computed from a Vision Transformers Masked Auto Encoder neural network, that was trained over Imagenet with image size 64 x 64. Embeddings can be visualized through PCA/T-SNE/UMAP projection from tensorboard framework, and we also provide code to visualize image content and labels with tensorboard. \n",
    "\n",
    "In this notebook we compute embeddings of weather image recognition dataset available <a href=\"https://www.kaggle.com/datasets/fceb22ab5e1d5288200c0f3016ccd626276983ca1fe8705ae2c32f7064d719de\">here<a> and holding CC0 licence.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sc8iJwc-Ec4",
    "outputId": "29d8169a-a423-48fe-9bfb-f04416094b01"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from models_mae import MaskedAutoencoderViT\n",
    "\n",
    "from functools import partial\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "import os \n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "inet_mean = [0.485, 0.456, 0.406]\n",
    "inet_std = [0.229, 0.224, 0.225]\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "from models_mae import MaskedAutoencoderViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating logs folders for tensorboard logs and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current = os.getcwd()\n",
    "DATA_PATH = current + '\\\\dataset' #folder to store images\n",
    "LOG_DIR = current + '\\\\logs'\n",
    "\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.mkdir(LOG_DIR)\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    from zipfile import ZipFile\n",
    "    with ZipFile(\"archive.zip\", 'r') as zObject: #the weather image recognition dataset provide this \"archive.zip\" file when it's downloaded from kaggle.\n",
    "        zObject.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that cuda is available to make things faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VkVGtDtJEWn",
    "outputId": "1f2342d8-353f-4f9f-84ce-592a6757bafc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "#Loading VitMAE model pretrained on imagenet 64*64\n",
    "\n",
    "n_heads = 16\n",
    "patch_size = 8\n",
    "img_size = 64\n",
    "num_patch = int((img_size/patch_size)**2)\n",
    "model = MaskedAutoencoderViT(\n",
    "        img_size=img_size,patch_size=patch_size, embed_dim=240, depth=10, num_heads=12,\n",
    "        decoder_embed_dim=160, decoder_depth=6, decoder_num_heads=n_heads,\n",
    "        mlp_ratio=4, norm_layer=partial(nn.LayerNorm, eps=1e-6))\n",
    "\n",
    "to_load = True\n",
    "file_name = 'checkpoint-99.pth'\n",
    "if to_load:\n",
    "    checkpoint = torch.load(file_name, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    print('Model loaded.')\n",
    "\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5Dn3QlJFPhS",
    "outputId": "420565b9-e23d-4a14-f9af-75feca9e8a10"
   },
   "outputs": [],
   "source": [
    "#Loading list of image files\n",
    "\n",
    "data_path_length = len(DATA_PATH)\n",
    "import glob\n",
    "classes_list = glob.glob(os.path.join(DATA_PATH, '*') )\n",
    "\n",
    "\n",
    "classes = {}\n",
    "\n",
    "k = 0\n",
    "imgs_list = []\n",
    "for k in range(len(classes_list)):\n",
    "    classes[str(k)] = classes_list[k][data_path_length:]  \n",
    "    class_imgs = glob.glob(os.path.join(classes_list[k], '*.jpg') )\n",
    "    for j in class_imgs:\n",
    "        imgs_list.append([j,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tensorboard won't be able to display more than 1500 images, so it is recommended to sample some of them for visualization. Here we sample among the 3 first classes.\n",
    "imgs_list = random.sample(imgs_list[:2662],1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4RL08J9-95s",
    "outputId": "7a424a7b-fab1-4aaa-ab5e-0bb6e4bd66d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:08<00:00, 168.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad images :  38  /  1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Filtering image with wrong number of channels or with resizing(encoding) errors\n",
    "img_size = 64\n",
    "channels = 3\n",
    "ref_shape =(img_size,img_size,channels)\n",
    "imgs_good_shape = []\n",
    "for i in tqdm(range(len(imgs_list))): #img = Image.open(img_path)\n",
    "    img = Image.open(imgs_list[i][0])\n",
    "    img = img.resize((img_size, img_size))\n",
    "    if np.array(img).shape==ref_shape:\n",
    "        imgs_good_shape.append(imgs_list[i])\n",
    "print('Number of bad images : ', len(imgs_list)-len(imgs_good_shape), ' / ', len(imgs_list))\n",
    "imgs_list = imgs_good_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ju46l-zeABI7"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DATA(Dataset):\n",
    "    def __init__(self, img_list, transform = None, mean = None,std = None,img_size = 64):\n",
    "        self.img_list = img_list\n",
    "        self.transform = None\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.img_size = img_size\n",
    "        self.normalize = None\n",
    "        if(self.mean is not None and self.std is not None):\n",
    "            self.normalize = transforms.Normalize(mean=self.mean,\n",
    "                         std=self.std)\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx, pil=False):\n",
    "        img_path = self.img_list[idx][0]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((img_size, img_size))\n",
    "        if pil:\n",
    "            return img,self.img_list[idx][1]\n",
    "        img = np.array(img)/255.              \n",
    "        img = torch.Tensor(img) \n",
    "        img = torch.einsum('hwc->chw', img) #Switch channel position\n",
    "        if self.normalize is not None:\n",
    "            img = self.normalize(img)\n",
    "        #img = tf.convert_to_tensor(img)\n",
    "        return img,self.img_list[idx][1]\n",
    "          \n",
    "weather = DATA(imgs_list, transform = None, mean = inet_mean,std = inet_std,img_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NvdkdMfFK75z"
   },
   "outputs": [],
   "source": [
    "#Some utils\n",
    "\n",
    "def get_embed(id,mask_ratio=0.75,grid_id=0):\n",
    "    img = weather.__getitem__(id)[0].unsqueeze(dim=0)\n",
    "    img = img.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        f0,_,_,_ = model.forward_encoder(img,mask_ratio = mask_ratio,grid_idx = grid_id)\n",
    "    f0 = f0[:, 1:, :] \n",
    "    return(f0.flatten())\n",
    "\n",
    "def get_img(id):\n",
    "    img = weather.__getitem__(id,pil=True)[0]\n",
    "    return(img)\n",
    "  \n",
    "def get_label(id):\n",
    "    return(weather.img_list[id][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate embeddings and sprites, might take some time depending on your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuAs0RCeOjfC",
    "outputId": "1a5e49b1-b960-4594-8374-81a4ea0ff9ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1462/1462 [00:33<00:00, 43.85it/s]\n"
     ]
    }
   ],
   "source": [
    "images_pil = []\n",
    "images_embeddings = []\n",
    "labels = []\n",
    "for x in tqdm(range(weather.__len__())): \n",
    "    img_pil = get_img(x)\n",
    "    img_embedding = get_embed(x)\n",
    "    images_embeddings.append(img_embedding.cpu().detach().numpy())\n",
    "    images_pil.append(np.array(img_pil))\n",
    "    # Assuming your output data is directly the label\n",
    "    label = get_label(x)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "f8RWWgQSU_fl"
   },
   "outputs": [],
   "source": [
    "def images_to_sprite(data):\n",
    "        #create sprite image and necessary padding\n",
    "        if len(data.shape) == 3:\n",
    "            data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "        data = data.astype(np.float32)\n",
    "        min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "        data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "        max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "        data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "\n",
    "        n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "        padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "                (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "        data = np.pad(data, padding, mode='constant',\n",
    "                constant_values=0)\n",
    "\n",
    "        data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "                + tuple(range(4, data.ndim + 1)))\n",
    "        data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "        data = (data * 255).astype(np.uint8)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWBqrEzfTOzr",
    "outputId": "146a0deb-1504-45c4-e0fb-d8218fb76f54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sprite = images_to_sprite(np.array(images_pil))\n",
    "cv2.imwrite(f'{LOG_DIR}/sprite.jpg', sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3LTqFgWbSI48"
   },
   "outputs": [],
   "source": [
    "with open(f'{LOG_DIR}/feature_vecs.tsv', 'w') as fw:\n",
    "    csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "    csv_writer.writerows(images_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "jkC4_t-uVhyA"
   },
   "outputs": [],
   "source": [
    "with open(f'{LOG_DIR}/metadata.tsv', 'w') as file: \n",
    "    for label in labels:\n",
    "        #file.write(f\"{classes[str(label)]}\\n\")\n",
    "        file.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "puf-eqHflJPF",
    "outputId": "d4c97e13-51b6-48a9-b2fb-b40183e90a50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to get size of each image\n",
    "int(np.ceil(np.sqrt(np.array(images_pil).shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build proper config file for tensorboard and then visualize the embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFmjcu8UATke"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This will be written in the config file.\n",
    "embeddings {\n",
    "  metadata_path: \"metadata.tsv\"\n",
    "  tensor_path: \"feature_vecs.tsv\"\n",
    "  sprite {\n",
    "    image_path: \"sprite.jpg\"\n",
    "    single_image_dim: 45\n",
    "    single_image_dim: 45\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "text_file = open(\"logs/projector_config.pbtxt\", \"w\")\n",
    " \n",
    "text_file.write('embeddings {\\n  metadata_path: \"metadata.tsv\"\\n  tensor_path: \"feature_vecs.tsv\"\\n  sprite {\\n    image_path: \"sprite.jpg\"\\n    single_image_dim: 45\\n    single_image_dim: 45\\n  }\\n}')\n",
    " \n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6S1SC1bWgZEo",
    "outputId": "e890a353-3b13-4b71-fa29-55d325686df2"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UXcFWpInrLa"
   },
   "outputs": [],
   "source": [
    "#%reload_ext tensorboard #In case you made some experiments and whant to display another tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs #With some notebooks (s.a jupyterlab) you might need to execute the two cells, and the second one will display tensorboard. Then just go to \"Projector\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs #Tensorboard will launch below this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On Windows, you might not be able to kill tensorboard process. In this case you should clear its data by removing this fodler : C:\\Users\\USER\\AppData\\Local\\Temp\\.tensorboard-info"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
